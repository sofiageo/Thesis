\section{CUDA}
\subsection{Εισαγωγή}
To CUDA είναι μια πλατφόρμα παράλληλου υπολογισμού, που δημιουργήθηκε από την NVIDIA και υλοποιήθηκε στις κάρτες γραφικών τις οποίες παράγει η ίδια. Το CUDA δίνει στους προγραμματιστές άμεση πρόσβαση στο σετ εικονικών εντολών και την μνήμη των στοιχείων του παράλληλου υπολογισμού σε κάρτες γραφικών NVIDIA. 

Αξιοποιώντας το CUDA, οι κάρτες γραφικών(GPU) μπορούν να χρησιμοποιηθούν για υπολογισμό γενικής χρήσης (δηλαδή όχι αποκλειστικά για γραφικά).Οι GPU έχουν μια αρχιτεκτονική παράλληλης εξόδου η οποία δίνει έμφαση στην εκτέλεση πολλών threads με μικρή ταχύτητα, σε αντίθεση με τις CPU όπου εκτελείται ένα thread με μεγάλη ταχύτητα. 

\begin{figure}[h]
\centering
\includegraphics[scale=0.50]{nvidia-cuda}
\caption{Βιολογία και πληροφορική}
\end{figure}

Η πλατφόρμα CUDA είναι προσβάσιμη στους προγραμματιστές μέσω βιβλιοθηκών, εντολών μεταγλώττισης, και προεκτάσεων σε γλώσσες προγραμματισμού βιομηχανικής κλίμακας, όπως η C, C++ και Fortran.

Οι προγραμματιστές της C/C++, χρησιμοποιούν το CUDA C/C++, μεταγλωττισμένο με το nvcc, έναν LLVM βασισμένο μεταγλωττιστή, και οι προγραμματιστές της Fortran χρησιμοποιούν το CUDA Fortran, μεταγλωττισμένο με τον μεταγλωττιστή PGI CUDA Fortran απο το The Portland Group. Εκτώς απο τα παραπάνω, η πλατφόρμα CUDA υποστηρίζει και άλλες διεπαφές υπολογισμού, όπως το OpenCL του Khronos Group, το DirectCompute της Microsoft, και το C++ AMP.

Στην βιομηχανία των υπολογιστών, οι GPUs δεν χρησιμοποιούνται μόνο για τα γραφικά αλλά και στους υπολογισμούς φυσικής παιχνιδιών (π.χ καπνός, φωτιά, ροή υγρών). Γνωστά παραδείγματα αποτελούν οι μηχανές PhysX και η Bullet. Το CUDA επίσης χρησιμοποιείται για να επιταχύνει μη-γραφικές εφαρμογές στην βιοπληροφορική, στην κρυπτογραφία, και σε πολλά άλλα πεδία.

Γενικότερα, η υπολογιστική δύναμη της GPU, βασίζεται στην παράλληλη αρχιτεκτονική της. Για αυτό, η πλατφόρμα του CUDA παρουσιάζει το νήμα(thread) ως το μικρότερο στοιχείο παραλληλισμού. Όμως, σε σύγκριση με την κεντρική μονάδα επεξεργασίας, τα νήματα της GPU έχουν μικρότερο κόστος χρήσης πόρων και μικρότερο κόστος δημιουργίας και αντικατάστασης.

Σημειώνεται ότι οι GPU είναι αποτελεσματικές, μόνο όταν τρέχει μεγάλος αριθμός απο τέτοια νήματα. Μια ομάδα από νήματα, που εκτελούνται παράλληλα, επικοινωνούν και συγχρονίζονται μεταξύ τους ονομάζεται block. Ο μέγιστος αριθμός των νημάτων σε ενα block είναι ένας περιορισμός που υπάρχει στην κάθε μονάδα γραφικής επεξεργασίας. Τέλος, μια ομάδα από blocks τα οποία έχουν την ίδια διάσταση και εκτελούνται απο το ίδιο πρόγραμμα CUDA παράλληλα, ονομάζεται πλέγμα.

Για να επιτρέψει βέλτιστη επίδοση για διαφορετικά πρότυπα, το CUDA εκτελεί ένα ιεραρχικό μοντέλο μνήμης, αντίθετα με τα παραδοσιακά μοντέλα που συναντάμε συνήθως στους υπολογιστές. Ο υπολογιστής και η συσκευή, έχουν τις δικές τους περιοχές μνήμης, τις οποίες ονομάζουν host memory και device memory, αντίστοιχα. Το CUDA παρέχει βελτιστοποιημένες λειτουργίες για να μεταφέρει δεδομένα από και προς αυτούς τους ξεχωριστούς χώρους.
Κάθε νήμα κατέχει το δικό του αρχείο καταχώρησης, το οποίο μπορεί να προσπελαστεί και να εγγραφεί.

Επιπλέον, μπορεί να προσπελάσει το δικό του αντίγραφο της τοπικής μνήμης. Όλα τα νήματα στο ίδιο πλέγμα μπορούν να προσπελάσουν και να γράψουν στην περιοχή της κοινόχρηστης μνήμης (shared memory). Για να αποφευχθούν κίνδυνοι από ταυτόχρονη προσπέλαση, μηχανισμοί συγχρονισμού νημάτων πρέπει να χρησιμοποιηθούν. Η κοινόχρηστη μνήμη, είναι οργανωμένη σε ομάδες που ονομάζονται τράπεζες, οι οποίες μπορούν να προσπελαστούν παράλληλα. Όλα τα νήματα έχουν επίσης πρόσβαση στον χώρο μνήμης που ονομάζεται καθολική μνήμη (global memory) και στις περιοχές που ονομάζονται μνήμη σταθερών (constant memory) και μνήμη υφής (texture memory).

\subsection{Πλεονεκτήματα}
Το CUDA έχει τα εξής πλεονεκτήματα σε σχέση με τους παραδοσιακούς τρόπους υπολογισμού γενικής χρήσης που εκτελούνται μέσω προγραμματιστικών διεπαφών γραφικών:
\begin{itemize}
\item Διασκορπισμένες προσπελάσεις - ο κώδικας μπορεί να διαβαστεί από αυθαίρετες διευθύνσεις στην μνήμη.
\item Ενοποιημένη εικονική μνήμη (CUDA 6)
\item Κοινόχρηστη μνήμη - το CUDA εκθέτει μια γρήγορη περιοχή κοινόχρηστης μνήμης (μέχρι 48KB για κάθε επεξεργαστή) η οποία μπορεί να μοιραστεί ανάμεσα στα threads. Αυτή μπορεί να χρησιμοποιηθεί σαν κρυφή μνήμη διαχειρίσιμη απο τον χρήστη, επιτρέποντας μεγαλύτερο εύρος δεδομένων απο ότι είναι δυνατό με τις προσπελάσεις υφών.
\item Πιο γρήγορες μεταφορτώσεις και προσπελάσεις από και προς την GPU
\item Πλήρης υποστήριξη για ακέραιες και bitwise λειτουργίες, για παράδειγμα τις προσπελάσεις υφών.
\end{itemize}
\subsection{Περιορισμοί}
 Το CUDA δεν υποστηρίζει ολόκληρο το πρότυπο της γλώσσας C, καθώς τρέχει μέσω ενός μεταγλωττιστή C++, ο οποίος εμποδίζει συγκεκριμένα μέρη της γλώσσας C να μεταγλωττιστούν.
\begin{table}
\begin{tabular}{ | c | c |}
Feature support (unlisted features are\\ supported for all compute capabilities) & Compute capability (version)\\ \hline
\end{tabular}
\end{table}

\subsection{Μνήμη}
\subsubsection{Κοινή μνήμη και συγχρονισμός}
Ο μεταγλωττιστής CUDA C μεταχειρίζεται τις μεταβλητές στην κοινή μνήμη με διαφορετικό τρόπο απο ότι τις τυπικές μεταβλητές. Δημιουργεί ένα αντίγραφο για κάθε block που εκτελείται στην CPU. Κάθε νήμα σε αυτό το block μοιράζεται την μνήμη, αλλά τα νήματα δεν μπορούν να προσπελάσουν και να επεξεργαστούν το αντίγραφο της μεταβλητής που φαίνεται στα άλλα blocks.

Αυτό παρέχει ένα καλό τρόπο με τον οποίο τα νήματα μέσα σε ένα block μπορούν να επικοινωνούν και να συνεργάζονται στους υπολογισμούς. Επιπλέον, τα buffers κοινής μνήμης βρίσκονται πάνω στην GPU, με αυτον τον τρόπο, η καθυστέρηση στην προσπέλαση της κοινής μνήμης είναι πολύ μικρότερη από ότι στα τυπικά buffers, καθιστώντας την κοινή μνήμη πολύ αποδοτική.

Η επικοινωνία μεταξύ των νημάτων, αν και πολύ ενδιαφέρουσα, χρειάζεται έναν μηχανισμό για τον συγχρονισμό της. Για παράδειγμα, αν το νήμα Α γράψει μια τιμή στην κοινή μνήμη και θέλουμε το νήμα Β να κάνει κάτι με αυτήν την τιμή, δεν μπορούμε να ξεκινήσουμε το νήμα Β έως ότου γνωρίζουμε ότι η εγγραφή από το νήμα Α ολοκληρώθηκε. Χωρίς τον συγχρονισμό, θα είχαμε έναν αγώνα δρόμου όπου το σωστό αποτέλεσμα της εκτέλεσης θα εξαρτάται από μη ντετερμινιστικά χαρακτηριστικά του υλικού.
\subsubsection{Σταθερή μνήμη}
Έχουμε αναλύσει το πως οι μοντέρνες GPUs είναι εφοδιασμένες με τεράστιες δυνατότητες υπολογιστικής δύναμης. Το υπολογιστικό πλεονέκτημα που έχουν οι μονάδες επεξεργασίας γραφικών βοήθησε στην ανάπτυξη του προγραμματισμού γενικού σκοπού. Με εκατοντάδες αριθμητικές μονάδες στην GPU, συνήθως ο περιορισμός δεν είναι η αριθμητική απόδοση, αλλά το εύρος ζώνης της μνήμης. Υπάρχουν τόσες πολλές ALUs στους επεξεργαστές γραφικών, όπου πολλές φορές δεν προλαβαίνουμε να μεταφέρουμε τα δεδομένα αρκετά γρήγορα ώστε να διατηρήσουμε έναν υψηλό ρυθμό υπολογισμού. 

Η γλώσσα CUDA παρέχει άλλον έναν τύπο μνήμης γνωστή ως σταθερή μνήμη. Όπως φαίνεται από το όνομα, χρησιμοποιούμε την σταθερή μνήμη για δεδομένα που δεν αλλάζουν κατά την διάρκεια μιας εκτέλεσης πυρήνα. Το υλικό NVIDIA παρέχει 64KB σταθερής μνήμης που χρησιμοποιεί με διαφορετικό τρόπο από ότι την γενική μνήμη. Σε μερικές περιπτώσεις, η χρήση της σταθερής μνήμης αντί της γενικής μνήμης μειώνει το εύρος ζώνης της μνήμης. 

Δηλώνοντας την μνήμη σαν σταθερή, περιορίζουμε την χρήση της σε ανάγνωσης μόνο. Λόγω αυτού του περιορισμού, περιμένουμε να κερδίσουμε κάτι από αυτήν την διαδικασία. Η χρήση σταθερής μνήμης μπορεί να μας διαφυλάξει εύρος μνήμης σε σχέση με την ανάγνωση των δεδομένων από την γενική μνήμη. Υπάρχουν δύο λόγοι γιατί η ανάγνωση από την σταθερή μνήμη των 64KB μπορεί να διαφυλάξει εύρος μνήμης:
\begin{itemize}
\item Μια ανάγνωση από την σταθερή μνήμη μπορεί να αναμεταδοθεί σε κοντινά νήματα, σώζοντας μας έως και 15 αναγνώσεις.
\item Η σταθερή μνήμη είναι cached, έτσι επόμενες αναγνώσεις της ίδιας διεύθυνσης δεν θα δημιουργήσουν επιπλέον κίνηση στην μνήμη.
\end{itemize}
Για να εξηγήσουμε αυτήν την δήλωση και το τι είναι τα κοντινά νήματα, σκεφτόμαστε την περίπτωση της ύφανσης. Στην ύφανση, το στημόνι αναφέρεται σε ένα σύνολο από νήματα, που υφαίνονται μαζί σε ένα ύφασμα. Στην αρχιτεκτονική CUDA, το στημόνι αναφέρεται σε μια συλλογή από 32 νήματα τα οποία υφαίνονται μεταξύ τους, και εκτελούνται αμφίδρομα. Σε κάθε γραμμή του κώδικα, κάθε νήμα από το στημόνι εκτελεί την ίδια διαδικασία, σε διαφορετικά δεδομένα.
Όσον αφορά τον χειρισμό της σταθερής μνήμης, το υλικό NVIDIA μπορεί να αναμεταδώσει μια απλή ανάγνωση σε μια ομάδα απο 16 νήματα: τα μισά από τα 32 νήματα που βρίσκονται στο στημόνι. Αν κάθε νήμα ζητάει δεδομένα απο την ίδια διεύθυνση της σταθερής μνήμης, η μονάδα επεξεργασίας γραφικών θα εκτελέσει μόνο ένα αίτημα ανάγνωσης και θα αναμεταδώσει τα δεδομένα σε όλα τα νήματα. Αν η ανάγνωση γίνεται απο την σταθερή μνήμη για μεγάλο όγκο πληροφοριών, θα δημιουργηθεί κίνηση που αντιστοιχεί μόνο στο 1/16 της κίνησης μνήμης που θα χρειαζόταν για την γενική μνήμη.

Τα πλεονεκτήματα όμως δεν σταματάνε εκεί. Επειδή έχουμε αποφασίσει να αφήσουμε άθικτη την μνήμη, το υλικό μπορεί να αποθηκεύσει τα σταθερά δεδομένα στην GPU. Έτσι μετά από την πρώτη ανάγνωση από την διεύθυνση της σταθερής μνήμης, όλες οι επόμενες αναγνώσεις δεν θα δημιουργήσουν επιπλέον κίνηση στην μνήμη. Δυστυχώς, μπορεί να υπάρξουν στιγμές που η απόδοση να μειώνεται λόγω της σταθερής μνήμης. Η αναμετάδοση μέρους από το στημόνι είναι ένα δίκοπο μαχαίρι. Αν και μπορεί να επιταχύνει την απόδοση όταν τα 16 νήματα διαβάζουν την ίδια διεύθυνση, μπορεί αντίστοιχα να μειώσει την απόδοση όταν τα 16 νήματα διαβάζουν διαφορετικές διευθύνσεις. Για παράδειγμα, αν τα 16 νήματα χρειάζονται διαφορετικά δεδομένα απο την σταθερή μνήμη, οι 16 αναγνώσεις θα γίνονταν με την σειρά, και θα χρειάζονταν 16 φορές περισσότερο χρόνο για να εκτελέσουν την εντολή. Αν διάβαζαν απο την γενική μνήμη, η εντολή θα δινόταν άμεσα. Σε αυτήν την περίπτωση, η ανάγνωση απο την σταθερή μνήμη θα ήταν πιο αργή από το να γινόταν ανάγνωση της γενικής μνήμης.


\subsection{CUDA streams}
Εξηγήσαμε το πως ο παράλληλος προγραμματισμός δεδομένων σε μια GPU μπορεί να δώσει εντυπωσιακά αποτελέσματα σε σχέση με την εκτέλεση σε CPU. Όμως υπάρχει ακόμα ένας τύπος παράλληλου υπολογισμού που μπορούμε να εκμεταλλευτούμε σε μια μονάδα επεξεργασίας γραφικών NVIDIA. Ο παραλληλισμός αυτός μοιάζει με αυτόν που συμβαίνει στα πολυ-νηματικά προγράμματα CPU. Αντί να εκτελούμε την ίδια διαδικασία σε πολλά στοιχεία δεδομένων όπως στον παραλληλισμό δεδομένων, ο παραλληλισμός έργων περιλαμβάνει παράλληλη εκτέλεση δύο η περισσότερων έργων. 

Σαν έργο μπορούμε να θεωρήσουμε μεγάλο αριθμό πραγμάτων. Για παράδειγμα, μια εφαρμογή μπορεί να εκτελεί δύο έργα: επανασχεδίαση του γραφικού περιβάλλοντος με ένα νήμα, και μεταφόρτωση μιας αναβάθμισης μέσω δικτύου με κάποιο άλλο νήμα. Αυτά τα έργα εκτελούνται παράλληλα, και ας μην έχουν τίποτε κοινό. Αν και ο παραλληλισμός έργων δεν είναι τόσο ευέλικτος όσο στις CPUs, συνεχίζει να μας προσφέρει ευκαιρίες για να αποκτήσουμε περισσότερη ταχύτητα από τις βασισμένες σε GPU εφαρμογές μας.

Τα CUDA streams, παίζουν μεγάλο ρόλο στην επιτάχυνση των εφαρμογών μας. Ένα CUDA stream αντιπροσωπεύει μια λίστα από GPU διεργασίες που θα εκτελεσθούν με συγκεκριμένη σειρά. Οι διεργασίες μπορούν να περιλαμβάνουν εκτελέσεις πυρήνων, αντιγραφές μνήμης, και εκκινήσεις/τερματισμούς συμβάντων ενός stream. H σειρά εισαγωγής των διεργασιών ορίζει την σειρά εκτέλεσης τους, με ευκαιρίες για αυτά τα έργα να εκτελεστούν παράλληλα.

%TODO: STUFF MISSING here 